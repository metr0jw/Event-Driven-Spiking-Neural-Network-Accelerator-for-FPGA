# Learning Engine Optimization - Quick Reference

## ğŸš€ Quick Start (30 seconds)

```bash
cd hardware/hls/test
make -f Makefile.optimization test_all
```

## ğŸ“Š Strategy Selection (Choose ONE)

### By Network Size
- **â‰¤64 neurons**: Active Tracking (21Ã— speedup @ 10% activity)
- **128-256 neurons**: Hierarchical (3-8Ã— speedup)
- **256+ neurons**: CAM Lookup (32Ã— speedup, constant time)

### By Activity Rate
- **<10% (sparse)**: Active Tracking
- **10-30%**: Active Tracking
- **30-50%**: Hierarchical
- **50-70%**: Dataflow
- **>70% (dense)**: Baseline

### By Application
- **MNIST/CIFAR**: Active Tracking
- **DVS events**: Active Tracking
- **Audio**: Hierarchical
- **Video**: Dataflow
- **Dense inference**: Baseline or Dataflow

## ğŸ”§ Configuration

Edit `hardware/hls/src/snn_learning_engine_optimized.cpp`:

```cpp
// Uncomment ONE strategy:
// #define OPT_STRATEGY_BASELINE          // Original (128 cycles)
#define OPT_STRATEGY_ACTIVE_TRACKING   // Best for sparse (6-64 cycles)
// #define OPT_STRATEGY_CAM_LOOKUP        // Best for large (4 cycles)
// #define OPT_STRATEGY_DATAFLOW          // Best for throughput (2Ã— parallel)
// #define OPT_STRATEGY_HIERARCHICAL      // Best for medium (16-96 cycles)
```

## ğŸ“ˆ Performance Summary

| Strategy | Best Speedup | Best For | Resource Cost |
|----------|-------------|----------|---------------|
| **Active Tracking** | 21Ã— @ 10% | Typical SNNs | +25% LUT |
| **CAM Lookup** | 32Ã— (constant) | Large networks | +300% LUT |
| **Dataflow** | 2Ã— (parallel) | High throughput | +100% all |
| **Hierarchical** | 8Ã— @ 10% | Medium networks | +50% LUT |

## ğŸ¯ Tuning Parameters

### Active Tracking
```cpp
const int MAX_ACTIVE_NEURONS = 16;  // 8, 16, 32 (2Ã— expected active)
const int CLEANUP_INTERVAL = 1000;  // 500, 1000, 2000 cycles
```

### CAM Lookup
```cpp
const int CAM_SIZE = 32;            // 16, 32, 64 (power of 2)
const int CAM_UNROLL_FACTOR = 8;    // 4, 8, 16 (parallel factor)
```

### Hierarchical
```cpp
const int NUM_TIME_BINS = 8;        // 4, 8, 16 (more = finer)
```

## ğŸ§ª Testing

```bash
# Test specific strategy
make -f Makefile.optimization test_active_tracking

# Performance benchmark
make -f Makefile.optimization benchmark_all

# HLS synthesis (requires Vivado HLS)
make -f Makefile.optimization synth_active_tracking

# Resource comparison
make -f Makefile.optimization resource_report
```

## ğŸ“‹ Expected Performance

### Active Tracking (Recommended for Most Cases)
| Activity | Latency | Speedup |
|----------|---------|---------|
| 10%      | 6 cycles | 21Ã— |
| 25%      | 16 cycles | 8Ã— |
| 50%      | 32 cycles | 4Ã— |

### CAM Lookup (Best for Large Networks)
- Constant **4 cycles** regardless of size or activity
- 32Ã— speedup for 64 neurons
- 128Ã— speedup for 256 neurons

### Dataflow (Best for Mixed Workloads)
- **2Ã— throughput** for mixed pre/post spikes
- Parallel processing of LTP and LTD
- Best when both spike types active

### Hierarchical (Balanced Approach)
| Bin Distribution | Latency | Speedup |
|-----------------|---------|---------|
| Uniform sparse  | 16 cycles | 8Ã— |
| Clustered       | 64 cycles | 2Ã— |

## ğŸ” Decision Tree

```
Network size?
â”œâ”€ â‰¤64 neurons
â”‚  â”œâ”€ Activity <30%? â†’ Active Tracking âœ“
â”‚  â””â”€ Activity >30%? â†’ Baseline or Dataflow
â”œâ”€ 64-256 neurons
â”‚  â”œâ”€ Temporal patterns? â†’ Hierarchical âœ“
â”‚  â””â”€ Random activity? â†’ Active Tracking
â””â”€ >256 neurons
   â”œâ”€ LUTs available? â†’ CAM Lookup âœ“
   â””â”€ Limited resources? â†’ Hierarchical
```

## ğŸš¨ Common Issues

**"Active list full"** â†’ Increase `MAX_ACTIVE_NEURONS`
**"Too many LUTs"** â†’ Reduce `CAM_SIZE` or use Active Tracking
**"Dataflow deadlock"** â†’ Increase FIFO `depth=64`
**"Timing violation"** â†’ Reduce `UNROLL_FACTOR`

## ğŸ“š Files Created

```
hardware/hls/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ snn_learning_engine_optimized.cpp  (5 strategies)
â”œâ”€â”€ include/
â”‚   â””â”€â”€ snn_learning_engine_optimized.h
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ tb_learning_engine_optimized.cpp   (comprehensive tests)
â”‚   â””â”€â”€ Makefile.optimization               (build system)
â””â”€â”€ docs/
    â”œâ”€â”€ LEARNING_ENGINE_OPTIMIZATION.md      (detailed guide)
    â””â”€â”€ OPTIMIZATION_IMPLEMENTATION_GUIDE.md (complete reference)
```

## ğŸ’¡ Recommendations by Platform

### PYNQ-Z2 (Zynq-7020)
- **Recommended**: Active Tracking
- **Resources**: 53,200 LUTs, 106,400 FFs
- **Fits**: Active (2.5K LUT), Hierarchical (3K LUT)
- **Avoid**: CAM (8K LUT may be tight)

### Zynq UltraScale+ ZU3EG
- **Recommended**: Hierarchical or CAM
- **Resources**: 71,060 LUTs, 141,680 FFs
- **Fits**: All strategies
- **Best**: CAM for maximum performance

### Zynq-7010 (Resource Constrained)
- **Recommended**: Baseline or Active (small)
- **Resources**: 17,600 LUTs, 35,200 FFs
- **Tune**: `MAX_ACTIVE_NEURONS = 8`

## ğŸ“ Implementation Steps

1. **Test in Software**
   ```bash
   make -f Makefile.optimization test_active_tracking
   ```

2. **Verify Correctness**
   - Check all 6 tests pass
   - Review STDP rule compliance

3. **Measure Performance**
   ```bash
   make -f Makefile.optimization benchmark_all
   ```

4. **Synthesize**
   ```bash
   make -f Makefile.optimization synth_active_tracking
   ```

5. **Check Resources**
   - Review synthesis report
   - Verify timing closure
   - Confirm BRAM/DSP usage

6. **Integrate**
   - Replace original learning engine
   - Update HLS scripts
   - Full system test

## ğŸ† Best Practices

âœ… **DO**:
- Start with Active Tracking for typical SNNs
- Profile your actual spike patterns
- Tune parameters based on measurements
- Test multiple strategies if resources allow

âŒ **DON'T**:
- Use CAM on small FPGAs
- Skip software testing before HLS
- Ignore resource reports
- Over-optimize for unrealistic workloads

## ğŸ“ Need Help?

See full documentation:
- `OPTIMIZATION_IMPLEMENTATION_GUIDE.md` - Complete reference
- `LEARNING_ENGINE_OPTIMIZATION.md` - Algorithm details
- `tb_learning_engine_optimized.cpp` - Test examples

---

**TL;DR**: Use **Active Tracking** for typical SNNs (5-20% activity). It gives 4-21Ã— speedup with only 25% more resources.
